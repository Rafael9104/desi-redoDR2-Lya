{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e36bf5-5376-48e8-8d93-15cb277d8f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Python packages\n",
    "\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from matplotlib import pylab as plt\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af16a4-44da-435b-b50a-46014e55758d",
   "metadata": {},
   "source": [
    "# Importing DR2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21056ffd-bd23-437b-95ce-099805bfa0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the location of baseline DR2 data\n",
    "DR2_lya_path = '/path/of/location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28356ade-22a8-4bbb-9524-e859c29d35f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_DR2 = {\n",
    "    'ciii': fits.open(f'{DR2_lya_path}/deltas/delta-ciii-2-0/Log/delta_attributes.fits.gz'),\n",
    "    'lya': fits.open(f'{DR2_lya_path}/deltas/delta-lya-3-0/Log/delta_attributes.fits.gz'),\n",
    "    'lyb': fits.open(f'{DR2_lya_path}/deltas/delta-lyb-3-0/Log/delta_attributes.fits.gz')\n",
    "}\n",
    "\n",
    "correlation_functions_DR2 = {\n",
    "    'lyalya': fits.open(f'{DR2_lya_path}/correlations/correlation-lyalya-3-0-0/cf_lya_x_lya_exp.fits'),\n",
    "    'lyalyb': fits.open(f'{DR2_lya_path}/correlations/correlation-lyalyb-3-0-0/cf_lya_x_lyb_exp.fits'),\n",
    "    'qsolya': fits.open(f'{DR2_lya_path}/correlations/correlation-qsolya-3-0-0/cf_qso_x_lya_exp.fits'),\n",
    "    'qsolyb': fits.open(f'{DR2_lya_path}/correlations/correlation-qsolyb-3-0-0/cf_qso_x_lyb_exp.fits')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0580f32a-bfeb-4dab-838d-34620481a992",
   "metadata": {},
   "source": [
    "# Importing Re-gunning results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e23649-2f35-4608-87e6-3e534d257a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the folder in your user where the re-do is located\n",
    "redo_path = '/path/of/user/location'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c12e7-ba5f-498f-ac87-efacfad430fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_redo = {\n",
    "    'ciii': fits.open(f'{redo_path}/deltas/delta-ciii-2-0/Log/delta_attributes.fits.gz'),\n",
    "    'lya': fits.open(f'{redo_path}/deltas/delta-lya-3-0/Log/delta_attributes.fits.gz'),\n",
    "    'lyb': fits.open(f'{redo_path}/deltas/delta-lyb-3-0/Log/delta_attributes.fits.gz')\n",
    "}\n",
    "\n",
    "correlation_functions_redo = {\n",
    "    'lyalya': fits.open(f'{redo_path}/correlations/correlation-lyalya-3-0-0/cf_lya_x_lya_exp.fits'),\n",
    "    'lyalyb': fits.open(f'{redo_path}/correlations/correlation-lyalyb-3-0-0/cf_lya_x_lyb_exp.fits'),\n",
    "    'qsolya': fits.open(f'{redo_path}/correlations/correlation-qsolya-3-0-0/cf_qso_x_lya_exp.fits'),\n",
    "    'qsolyb': fits.open(f'{redo_path}/correlations/correlation-qsolyb-3-0-0/cf_qso_x_lyb_exp.fits')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04866f-47a9-4425-8f40-028ff2f6841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating subplots for each type of Re-do delta\n",
    "for name, hdul in deltas_redo.items():\n",
    "    # Create the same subplot structure for each delta\n",
    "    f, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "    axs[-1, -1].axis('off')\n",
    "    \n",
    "    # Set the main title for the entire figure\n",
    "    f.suptitle(f'Delta {name.upper()} Analysis', fontsize=16, y=1.02)\n",
    "\n",
    "    ### Stack Delta Plot\n",
    "    loglam = hdul['STACK_DELTAS'].data['LOGLAM'][:]\n",
    "    stack  = hdul['STACK_DELTAS'].data['STACK'][:]\n",
    "    cut = (stack != 0.) & (hdul['STACK_DELTAS'].data['WEIGHT'][:] > 0.)\n",
    "    loglam = loglam[cut]\n",
    "    stack  = stack[cut]\n",
    "    axs[0][0].plot(10.**loglam, stack, linewidth=1, color='blue')\n",
    "    axs[0][0].grid(alpha=0.3)\n",
    "    axs[0][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[0][0].set_ylabel(r'$\\mathrm{\\overline{Deltas}}$', fontsize=12)\n",
    "    axs[0][0].set_title('Stacked Deltas')\n",
    "\n",
    "    ### ETA Plot\n",
    "    loglam    = hdul['VAR_FUNC'].data['LOGLAM'][:]\n",
    "    eta       = hdul['VAR_FUNC'].data['ETA'][:]\n",
    "    nb_pixels = hdul['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "    cut = (nb_pixels > 0.) & (eta != 1.)\n",
    "    loglam = loglam[cut]\n",
    "    eta    = eta[cut]\n",
    "    axs[0][1].plot(10.**loglam, eta, linewidth=1, color='red')\n",
    "    axs[0][1].grid(alpha=0.3)\n",
    "    axs[0][1].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[0][1].set_ylabel(r'$\\eta$', fontsize=12)\n",
    "    axs[0][1].set_title('ETA')\n",
    "\n",
    "    ### VAR_LSS Plot\n",
    "    loglam    = hdul['VAR_FUNC'].data['LOGLAM'][:]\n",
    "    var_lss   = hdul['VAR_FUNC'].data['VAR_LSS'][:]\n",
    "    nb_pixels = hdul['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "    cut       = (nb_pixels > 0.) & (var_lss != 0.1)\n",
    "    loglam    = loglam[cut]\n",
    "    var_lss   = var_lss[cut]\n",
    "    axs[0][2].plot(10.**loglam, var_lss, linewidth=1, color='green')\n",
    "    axs[0][2].grid(alpha=0.3)\n",
    "    axs[0][2].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[0][2].set_ylabel(r'$\\sigma^{2}_{\\mathrm{LSS}}$', fontsize=12)\n",
    "    axs[0][2].set_title('VAR_LSS')\n",
    "\n",
    "    ### FUDGE Plot\n",
    "    loglam    = hdul['VAR_FUNC'].data['LOGLAM'][:]\n",
    "    fudge     = hdul['VAR_FUNC'].data['FUDGE'][:]\n",
    "    nb_pixels = hdul['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "    cut       = (nb_pixels > 0.) & (fudge != 1.e-7)\n",
    "    loglam    = loglam[cut]\n",
    "    fudge     = fudge[cut]\n",
    "    axs[1][0].plot(10.**loglam, fudge, linewidth=1, color='purple')\n",
    "    axs[1][0].grid(alpha=0.3)\n",
    "    axs[1][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[1][0].set_ylabel(r'$\\mathrm{Fudge}$', fontsize=12)\n",
    "    axs[1][0].set_title('FUDGE')\n",
    "\n",
    "    ### Mean Continuum Plot\n",
    "    loglam_rest = hdul['CONT'].data['LOGLAM_REST'][:]\n",
    "    mean_cont   = hdul['CONT'].data['MEAN_CONT'][:]\n",
    "    cut = (mean_cont != 0.) & (hdul['CONT'].data['WEIGHT'][:] > 0.)\n",
    "    loglam_rest = loglam_rest[cut]\n",
    "    mean_cont   = mean_cont[cut]\n",
    "    axs[1][1].plot(10.**loglam_rest, mean_cont, linewidth=1, color='orange')\n",
    "    axs[1][1].grid(alpha=0.3)\n",
    "    axs[1][1].set_xlabel(r'$\\lambda_{\\mathrm{R.F.}} \\, [\\AA]$', fontsize=12)\n",
    "    axs[1][1].set_ylabel(r'$\\mathrm{\\overline{Flux}}$', fontsize=12)\n",
    "    axs[1][1].set_title('Mean Continuum')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print some info about each delta\n",
    "    print(f\"=== Delta {name.upper()} Summary ===\")\n",
    "    print(f\"Stacked Deltas range: {np.min(stack):.3f} to {np.max(stack):.3f}\")\n",
    "    print(f\"ETA range: {np.min(eta):.3f} to {np.max(eta):.3f}\")\n",
    "    print(f\"VAR_LSS range: {np.min(var_lss):.3f} to {np.max(var_lss):.3f}\")\n",
    "    print(f\"FUDGE range: {np.min(fudge):.3e} to {np.max(fudge):.3e}\")\n",
    "    print(f\"Mean Continuum range: {np.min(mean_cont):.3f} to {np.max(mean_cont):.3f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a99b9-9a28-4693-b582-023daf4f3f77",
   "metadata": {},
   "source": [
    "## Comparison with DR2 Ly$\\alpha$ results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401aa8ad-5fed-43dc-b996-06d94359a5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot differences between deltas and deltasDR2 for all three types\n",
    "for name in deltas_redo.keys():\n",
    "    if name in deltas_DR2:  # Ensure the same delta exists in both dictionaries\n",
    "        # Create the same subplot structure for differences\n",
    "        f, axs = plt.subplots(nrows=2, ncols=3, figsize=(15, 10))\n",
    "        axs[-1, -1].axis('off')\n",
    "        \n",
    "        # Set the main title for the entire figure\n",
    "        f.suptitle(f'Differences: Delta {name.upper()} (deltas - deltas DR2)', fontsize=16, y=1.02)\n",
    "\n",
    "        # Get both HDU lists\n",
    "        hdul_orig = deltas_redo[name]\n",
    "        hdul_DR2 = deltas_DR2[name]\n",
    "\n",
    "        ### Stack Delta Difference Plot\n",
    "        loglam_orig = hdul_orig['STACK_DELTAS'].data['LOGLAM'][:]\n",
    "        stack_orig = hdul_orig['STACK_DELTAS'].data['STACK'][:]\n",
    "        cut_orig = (stack_orig != 0.) & (hdul_orig['STACK_DELTAS'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        loglam_DR2 = hdul_DR2['STACK_DELTAS'].data['LOGLAM'][:]\n",
    "        stack_DR2 = hdul_DR2['STACK_DELTAS'].data['STACK'][:]\n",
    "        cut_DR2 = (stack_DR2 != 0.) & (hdul_DR2['STACK_DELTAS'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        # Find common wavelength range\n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_DR2[cut_DR2])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            # Get values at common wavelengths\n",
    "            orig_vals = stack_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            DR2_vals = stack_DR2[cut_DR2][np.isin(loglam_DR2[cut_DR2], common_loglam)]\n",
    "            difference = orig_vals - DR2_vals\n",
    "            \n",
    "            axs[0][0].plot(10.**common_loglam, difference, linewidth=1, color='blue')\n",
    "            axs[0][0].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[0][0].grid(alpha=0.3)\n",
    "            axs[0][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[0][0].set_ylabel(r'$\\Delta \\mathrm{\\overline{Deltas}}$', fontsize=12)\n",
    "            axs[0][0].set_title('Stacked Deltas Difference')\n",
    "\n",
    "        ### ETA Difference Plot\n",
    "        loglam_orig = hdul_orig['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        eta_orig = hdul_orig['VAR_FUNC'].data['ETA'][:]\n",
    "        nb_pixels_orig = hdul_orig['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_orig = (nb_pixels_orig > 0.) & (eta_orig != 1.)\n",
    "        \n",
    "        loglam_DR2 = hdul_DR2['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        eta_DR2 = hdul_DR2['VAR_FUNC'].data['ETA'][:]\n",
    "        nb_pixels_DR2 = hdul_DR2['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_DR2 = (nb_pixels_DR2 > 0.) & (eta_DR2 != 1.)\n",
    "        \n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_DR2[cut_DR2])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            orig_vals = eta_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            DR2_vals = eta_DR2[cut_DR2][np.isin(loglam_DR2[cut_DR2], common_loglam)]\n",
    "            difference = orig_vals - DR2_vals\n",
    "            \n",
    "            axs[0][1].plot(10.**common_loglam, difference, linewidth=1, color='red')\n",
    "            axs[0][1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[0][1].grid(alpha=0.3)\n",
    "            axs[0][1].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[0][1].set_ylabel(r'$\\Delta \\eta$', fontsize=12)\n",
    "            axs[0][1].set_title('ETA Difference')\n",
    "\n",
    "        ### VAR_LSS Difference Plot\n",
    "        loglam_orig = hdul_orig['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        var_lss_orig = hdul_orig['VAR_FUNC'].data['VAR_LSS'][:]\n",
    "        nb_pixels_orig = hdul_orig['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_orig = (nb_pixels_orig > 0.) & (var_lss_orig != 0.1)\n",
    "        \n",
    "        loglam_DR2 = hdul_DR2['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        var_lss_DR2 = hdul_DR2['VAR_FUNC'].data['VAR_LSS'][:]\n",
    "        nb_pixels_DR2 = hdul_DR2['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_DR2 = (nb_pixels_DR2 > 0.) & (var_lss_DR2 != 0.1)\n",
    "        \n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_DR2[cut_DR2])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            orig_vals = var_lss_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            DR2_vals = var_lss_DR2[cut_DR2][np.isin(loglam_DR2[cut_DR2], common_loglam)]\n",
    "            difference = orig_vals - DR2_vals\n",
    "            \n",
    "            axs[0][2].plot(10.**common_loglam, difference, linewidth=1, color='green')\n",
    "            axs[0][2].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[0][2].grid(alpha=0.3)\n",
    "            axs[0][2].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[0][2].set_ylabel(r'$\\Delta \\sigma^{2}_{\\mathrm{LSS}}$', fontsize=12)\n",
    "            axs[0][2].set_title('VAR_LSS Difference')\n",
    "\n",
    "        ### FUDGE Difference Plot\n",
    "        loglam_orig = hdul_orig['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        fudge_orig = hdul_orig['VAR_FUNC'].data['FUDGE'][:]\n",
    "        nb_pixels_orig = hdul_orig['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_orig = (nb_pixels_orig > 0.) & (fudge_orig != 1.e-7)\n",
    "        \n",
    "        loglam_DR2 = hdul_DR2['VAR_FUNC'].data['LOGLAM'][:]\n",
    "        fudge_DR2 = hdul_DR2['VAR_FUNC'].data['FUDGE'][:]\n",
    "        nb_pixels_DR2 = hdul_DR2['VAR_FUNC'].data['NUM_PIXELS'][:]\n",
    "        cut_DR2 = (nb_pixels_DR2 > 0.) & (fudge_DR2 != 1.e-7)\n",
    "        \n",
    "        common_loglam = np.intersect1d(loglam_orig[cut_orig], loglam_DR2[cut_DR2])\n",
    "        \n",
    "        if len(common_loglam) > 0:\n",
    "            orig_vals = fudge_orig[cut_orig][np.isin(loglam_orig[cut_orig], common_loglam)]\n",
    "            DR2_vals = fudge_DR2[cut_DR2][np.isin(loglam_DR2[cut_DR2], common_loglam)]\n",
    "            difference = orig_vals - DR2_vals\n",
    "            \n",
    "            axs[1][0].plot(10.**common_loglam, difference, linewidth=1, color='purple')\n",
    "            axs[1][0].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[1][0].grid(alpha=0.3)\n",
    "            axs[1][0].set_xlabel(r'$\\lambda_{\\mathrm{Obs.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[1][0].set_ylabel(r'$\\Delta \\mathrm{Fudge}$', fontsize=12)\n",
    "            axs[1][0].set_title('FUDGE Difference')\n",
    "\n",
    "        ### Mean Continuum Difference Plot\n",
    "        loglam_rest_orig = hdul_orig['CONT'].data['LOGLAM_REST'][:]\n",
    "        mean_cont_orig = hdul_orig['CONT'].data['MEAN_CONT'][:]\n",
    "        cut_orig = (mean_cont_orig != 0.) & (hdul_orig['CONT'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        loglam_rest_DR2 = hdul_DR2['CONT'].data['LOGLAM_REST'][:]\n",
    "        mean_cont_DR2 = hdul_DR2['CONT'].data['MEAN_CONT'][:]\n",
    "        cut_DR2 = (mean_cont_DR2 != 0.) & (hdul_DR2['CONT'].data['WEIGHT'][:] > 0.)\n",
    "        \n",
    "        common_loglam_rest = np.intersect1d(loglam_rest_orig[cut_orig], loglam_rest_DR2[cut_DR2])\n",
    "        \n",
    "        if len(common_loglam_rest) > 0:\n",
    "            orig_vals = mean_cont_orig[cut_orig][np.isin(loglam_rest_orig[cut_orig], common_loglam_rest)]\n",
    "            DR2_vals = mean_cont_DR2[cut_DR2][np.isin(loglam_rest_DR2[cut_DR2], common_loglam_rest)]\n",
    "            difference = orig_vals - DR2_vals\n",
    "            \n",
    "            axs[1][1].plot(10.**common_loglam_rest, difference, linewidth=1, color='orange')\n",
    "            axs[1][1].axhline(y=0, color='red', linestyle='--', alpha=0.7)\n",
    "            axs[1][1].grid(alpha=0.3)\n",
    "            axs[1][1].set_xlabel(r'$\\lambda_{\\mathrm{R.F.}} \\, [\\AA]$', fontsize=12)\n",
    "            axs[1][1].set_ylabel(r'$\\Delta \\mathrm{\\overline{Flux}}$', fontsize=12)\n",
    "            axs[1][1].set_title('Mean Continuum Difference')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'delta-{name}-3-0.png')\n",
    "        plt.show()\n",
    "        \n",
    "        # Print statistics about the differences\n",
    "        print(f\"=== Delta {name.upper()} Difference Statistics ===\")\n",
    "        if len(common_loglam) > 0:\n",
    "            print(f\"Stacked Deltas diff - Mean: {np.mean(difference):.3e}, Std: {np.std(difference):.3e}\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7414ed1-061c-4c6b-be8c-b214697691bc",
   "metadata": {},
   "source": [
    "# Re-do and DR2 Correlation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e65ed4-7b1a-46a3-8df2-e9aee180d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating dictionaries to store the data that we will use to plot the Re-do correlations in (RP,RT) space\n",
    "\n",
    "correlation_data_redo = {}\n",
    "grid_coordinates_redo = {}\n",
    "\n",
    "# Processing all correlation functions from dictionary 'correlation_functions_redo'\n",
    "for name, hdul in correlation_functions_redo.items():\n",
    "    print(f\"Processing {name}...\")\n",
    "    \n",
    "    # Extracting correlation data, RP coordinate and RT coordinate with respect to line-of-sight (LOS)\n",
    "    corr_data = hdul['COR'].data['DA']\n",
    "    rp_data = hdul['COR'].data['RP']\n",
    "    rt_data = hdul['COR'].data['RT']\n",
    "    \n",
    "    # Determine grid size automatically\n",
    "    # For correlations with QSOs, we use fixed dimensions (100,50). \n",
    "    # For correlations without QSOs, we obtain the dimensions automatically (50,50).\n",
    "    if name.startswith('qso'):\n",
    "        n_parallel = 100\n",
    "        n_transverse = 50\n",
    "        print(f\" Using grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    else:\n",
    "        n_parallel = int(np.sqrt(corr_data.size))\n",
    "        n_transverse = n_parallel\n",
    "        print(f\" Using grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    \n",
    "    # Reshape the correlation data and their coordinates data\n",
    "    correlation_reshaped = corr_data.reshape(n_parallel, n_transverse)\n",
    "    rp_reshaped = rp_data.reshape(n_parallel, n_transverse)\n",
    "    rt_reshaped = rt_data.reshape(n_parallel, n_transverse)\n",
    "    \n",
    "    # Storing in empty dictionaries\n",
    "    correlation_data_redo[name] = {\n",
    "        'correlation': correlation_reshaped,\n",
    "        'original_data': corr_data\n",
    "    }\n",
    "    \n",
    "    grid_coordinates_redo[name] = {\n",
    "        'rp': rp_reshaped,\n",
    "        'rt': rt_reshaped,\n",
    "        'original_rp': rp_data,\n",
    "        'original_rt': rt_data\n",
    "    }\n",
    "\n",
    "print(\"All Re-do correlations were processed and stored in dictionaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b079afff-b350-49f5-ac7c-c23ae0345134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating dictionaries to store the data that we will use to plot the DR2 correlations in (RP,RT) space\n",
    "\n",
    "correlation_data_DR2 = {}\n",
    "grid_coordinates_DR2 = {}\n",
    "\n",
    "# Processing all correlation functions from dictionary 'correlation_functions_DR2'\n",
    "for name, hdul in correlation_functions_DR2.items():\n",
    "    print(f\"Processing DR2 {name}...\")\n",
    "\n",
    "    # Extracting correlation data, RP coordinate and RT coordinate with respect to line-of-sight (LOS)\n",
    "    corr_data = hdul['COR'].data['DA']\n",
    "    rp_data = hdul['COR'].data['RP']\n",
    "    rt_data = hdul['COR'].data['RT']\n",
    "    \n",
    "    # Determine grid size automatically\n",
    "    # For correlations with QSOs, we use fixed dimensions (100, 50). \n",
    "    # For correlations without QSOs, we obtain the dimensions automatically (50,50).\n",
    "    if name.startswith('qso'):\n",
    "        n_parallel = 100\n",
    "        n_transverse = 50\n",
    "        print(f\" Using grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    else:\n",
    "        n_parallel = int(np.sqrt(corr_data.size))\n",
    "        n_transverse = n_parallel\n",
    "        print(f\" Using automatic grid dimensions: ({n_parallel}, {n_transverse})\")\n",
    "    \n",
    "    # Reshape the correlation data and their coordinates data\n",
    "    correlation_reshaped = corr_data.reshape(n_parallel, n_transverse)\n",
    "    rp_reshaped = rp_data.reshape(n_parallel, n_transverse)\n",
    "    rt_reshaped = rt_data.reshape(n_parallel, n_transverse)\n",
    "    \n",
    "    # Storing in DR2 empty dictionaries\n",
    "    correlation_data_DR2[name] = {\n",
    "        'correlation': correlation_reshaped,\n",
    "        'original_data': corr_data\n",
    "    }\n",
    "    \n",
    "    grid_coordinates_DR2[name] = {\n",
    "        'rp': rp_reshaped,\n",
    "        'rt': rt_reshaped,\n",
    "        'original_rp': rp_data,\n",
    "        'original_rt': rt_data\n",
    "    }\n",
    "\n",
    "print(\"All DR2 correlations data were processed and stored in dictionaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7f7461-e4eb-4d0e-b7c0-ad3bcec4ff86",
   "metadata": {},
   "source": [
    "## Plotting Re-do correlation functions in ($r_{\\parallel}$, $r_{\\perp}$) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97a594-364b-4f9d-a9ac-cc65a52eb10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Re-do Correlation Functions\\n', fontsize=16, y=0.95)\n",
    "\n",
    "correlation_names = ['lyalya', 'lyalyb', 'qsolya', 'qsolyb']\n",
    "\n",
    "for idx, name in enumerate(correlation_names):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    # Getting data from dictionaries\n",
    "    corr = correlation_data_redo[name]['correlation']\n",
    "    rp = grid_coordinates_redo[name]['rp']\n",
    "    rt = grid_coordinates_redo[name]['rt']\n",
    "\n",
    "    # Calculating the value of the correlation bins to plot\n",
    "    plot_data = (rt**2 + rp**2) * corr\n",
    "    \n",
    "    # Use imshow with extent instead\n",
    "    extent = [rt.min(), rt.max(), rp.min(), rp.max()]\n",
    "    mesh = ax.imshow(plot_data, extent=extent, cmap='RdYlBu', \n",
    "                    aspect='auto', origin='lower')\n",
    "    \n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(r'$r^2\\xi$($r_{\\parallel}$, $r_{\\perp}$)', fontsize=12)\n",
    "    \n",
    "    ax.set_xlabel('$r_{\\perp}$ [Mpc/h]', fontsize=12)\n",
    "    ax.set_ylabel('$r_{\\parallel}$ [Mpc/h]', fontsize=12)\n",
    "    \n",
    "    titles = {\n",
    "        'lyalya': r'$Ly\\alpha$ x $Ly\\alpha$',\n",
    "        'lyalyb': r'$Ly\\alpha$ x $Ly\\beta$', \n",
    "        'qsolya': r'$QSO$ x $Ly\\alpha$',\n",
    "        'qsolyb': r'$QSO$ x $Ly\\beta$'\n",
    "    }\n",
    "    ax.set_title(titles[name], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'correlations-3-0-0.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dadba9-1bc1-4bff-b5ae-76b851dfecb3",
   "metadata": {},
   "source": [
    "## Comparison with DR2 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8aa37b-587d-4fcf-8f68-22c7c52dca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of the differences between Re-do and DR2 correlation functions\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Difference between Re-do and DR2 Correlation Functions\\n', fontsize=16, y=0.95)\n",
    "\n",
    "correlation_names = ['lyalya', 'lyalyb', 'qsolya', 'qsolyb']\n",
    "\n",
    "for idx, name in enumerate(correlation_names):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Getting data from DR2 dictionaries\n",
    "    corr_DR2 = correlation_data_DR2[name]['correlation']\n",
    "    rp_DR2 = grid_coordinates_DR2[name]['rp']\n",
    "    rt_DR2 = grid_coordinates_DR2[name]['rt']\n",
    "    \n",
    "    # Getting data from REDO dictionaries\n",
    "    corr_redo = correlation_data_redo[name]['correlation']\n",
    "    rp_redo = grid_coordinates_redo[name]['rp']\n",
    "    rt_redo = grid_coordinates_redo[name]['rt']\n",
    "    \n",
    "    # Calculating the difference: Re-do - DR2\n",
    "\n",
    "    difference = (rt_DR2**2 + rp_DR2**2) * (corr_redo - corr_DR2)\n",
    "    \n",
    "    # Use imshow with extent instead\n",
    "    extent = [rt_DR2.min(), rt_DR2.max(), rp_DR2.min(), rp_DR2.max()]\n",
    "    mesh = ax.imshow(difference, extent=extent, cmap='RdBu_r', \n",
    "                    aspect='auto', origin='lower')\n",
    "    \n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(r'$\\Delta~ r^2\\xi$($r_{\\parallel}$, $r_{\\perp}$)', fontsize=12)\n",
    "    \n",
    "    ax.set_xlabel('$r_{\\perp}$ [Mpc/h]', fontsize=12)\n",
    "    ax.set_ylabel('$r_{\\parallel}$ [Mpc/h]', fontsize=12)\n",
    "    \n",
    "    titles = {\n",
    "        'lyalya': r'$\\Delta$: $Ly\\alpha$ x $Ly\\alpha$',\n",
    "        'lyalyb': r'$\\Delta$: $Ly\\alpha$ x $Ly\\beta$', \n",
    "        'qsolya': r'$\\Delta$: $QSO$ x $Ly\\alpha$',\n",
    "        'qsolyb': r'$\\Delta$: $QSO$ x $Ly\\beta$'\n",
    "    }\n",
    "    ax.set_title(titles[name], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'delta_corr-3-0-0.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e1291-b94b-4acc-aa6e-04c2a51456d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots of the differences between Re-do and DR2 correlation functions\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Percentage error between Re-do and DR2 Correlation Functions\\n', fontsize=16, y=0.95)\n",
    "\n",
    "correlation_names = ['lyalya', 'lyalyb', 'qsolya', 'qsolyb']\n",
    "\n",
    "for idx, name in enumerate(correlation_names):\n",
    "    row = idx // 2\n",
    "    col = idx % 2\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Getting data from DR2 dictionaries\n",
    "    corr_DR2 = correlation_data_DR2[name]['correlation']\n",
    "    rp_DR2 = grid_coordinates_DR2[name]['rp']\n",
    "    rt_DR2 = grid_coordinates_DR2[name]['rt']\n",
    "    \n",
    "    # Getting data from REDO dictionaries\n",
    "    corr_redo = correlation_data_redo[name]['correlation']\n",
    "    rp_redo = grid_coordinates_redo[name]['rp']\n",
    "    rt_redo = grid_coordinates_redo[name]['rt']\n",
    "    \n",
    "    # Calculating the difference: Re-do - DR2\n",
    "\n",
    "    percentage_error = (np.abs(corr_DR2 - corr_redo)/np.abs(corr_DR2)) * 100\n",
    "    \n",
    "    # Use imshow with extent instead\n",
    "    extent = [rt_DR2.min(), rt_DR2.max(), rp_DR2.min(), rp_DR2.max()]\n",
    "    mesh = ax.imshow(percentage_error, extent=extent, cmap='viridis', \n",
    "                    aspect='auto', origin='lower')\n",
    "    \n",
    "    cbar = plt.colorbar(mesh, ax=ax)\n",
    "    cbar.set_label(r'$\\% err~ \\xi$($r_{\\parallel}$, $r_{\\perp}$)', fontsize=12)\n",
    "\n",
    "    # Formatter that preserves the number exactly and adds '%'\n",
    "    def add_percent(x, pos):\n",
    "        return f\"{x:g}%\"\n",
    "    \n",
    "    cbar.formatter = FuncFormatter(add_percent)\n",
    "    cbar.update_ticks()\n",
    "    \n",
    "    ax.set_xlabel('$r_{\\perp}$ [Mpc/h]', fontsize=12)\n",
    "    ax.set_ylabel('$r_{\\parallel}$ [Mpc/h]', fontsize=12)\n",
    "    \n",
    "    titles = {\n",
    "        'lyalya': r'$\\% err$: $Ly\\alpha$ x $Ly\\alpha$',\n",
    "        'lyalyb': r'$\\% err$: $Ly\\alpha$ x $Ly\\beta$', \n",
    "        'qsolya': r'$\\% err$: $QSO$ x $Ly\\alpha$',\n",
    "        'qsolyb': r'$\\% err$: $QSO$ x $Ly\\beta$'\n",
    "    }\n",
    "    ax.set_title(titles[name], fontsize=14)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'percentage_error_corr-3-0-0.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2869865-6b8e-4a46-8071-a8738214a03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
